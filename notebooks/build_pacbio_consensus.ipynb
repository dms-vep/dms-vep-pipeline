{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46cc8b5f-6062-4379-9165-0ef2ba6cf5a7",
   "metadata": {},
   "source": [
    "# Build PacBio consensus sequences\n",
    "This notebook builds consensus sequences for each barcode from the PacBio CCS sequencing.\n",
    "\n",
    "Import Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc6438-6309-483c-a94f-273e9488981b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import Bio.SeqIO\n",
    "\n",
    "import alignparse.consensus\n",
    "import alignparse.utils\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "import dms_variants.barcodes\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121841c-2e7f-49ec-b16e-a66bea9d2a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b67f83e-6dca-4217-bb0d-7291d1b032e6",
   "metadata": {},
   "source": [
    "Get configuration information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f63ece-f250-4e81-bdde-e03b8ce6b072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are running notebook interactively rather than in pipeline that handles\n",
    "# working directories, you may have to first `os.chdir` to appropriate directory.\n",
    "\n",
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678d44d-a9a7-42d7-841c-d3c8e169f296",
   "metadata": {},
   "source": [
    "Get the aligned CCSs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a458c-674c-40cd-9076-57c021ba315a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_ccs = pd.read_csv(config[\"aligned_ccs_file\"], na_filter=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7627ba-18b3-4427-8385-3e1caa567c06",
   "metadata": {},
   "source": [
    "Get the gene sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6492b1-0998-47e5-869b-9d4d8b470832",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geneseq = str(Bio.SeqIO.read(config[\"gene_sequence_codon\"], \"fasta\").seq)\n",
    "\n",
    "print(f\"Read gene of length {len(geneseq)} nucleotides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899eccd-c306-44f1-a53b-2a497d5fc593",
   "metadata": {},
   "source": [
    "## Identify strand exchange and filter CCSs known to have it\n",
    "Assign each CCS by which variant it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c3ab3-f73f-4177-8df8-2fae881fbe3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variant_tags = config[\"variant_tags\"]\n",
    "display(pd.DataFrame(variant_tags))\n",
    "\n",
    "# invert dictionary so tag identities given by nucleotide identity\n",
    "variant_tags_by_nt = {\n",
    "    tag: {val: key for key, val in vals.items()} for tag, vals in variant_tags.items()\n",
    "}\n",
    "assert all(\n",
    "    len(d1) == len(d2)\n",
    "    for d1, d2 in zip(variant_tags.items(), variant_tags_by_nt.items())\n",
    ")\n",
    "\n",
    "\n",
    "# function to assign strand exchange status\n",
    "def classify_strand_exchange(row):\n",
    "    tags = list({row[tag] for tag in variant_tags})\n",
    "    if len(tags) == 1:\n",
    "        return tags[0]\n",
    "    elif \"wildtype\" in tags:\n",
    "        return \"partially wildtype\"\n",
    "    elif \"invalid\" in tags:\n",
    "        return \"invalid nucleotide\"\n",
    "    else:\n",
    "        return \"strand exchange\"\n",
    "\n",
    "\n",
    "# assign strand exchange status\n",
    "for tag, d in variant_tags_by_nt.items():\n",
    "    aligned_ccs[tag] = aligned_ccs[f\"{tag}_sequence\"].map(d).fillna(\"invalid\")\n",
    "aligned_ccs[\"strand_exchange\"] = aligned_ccs.apply(classify_strand_exchange, axis=1)\n",
    "\n",
    "# get summary stats\n",
    "strand_exchange_stats = (\n",
    "    aligned_ccs.groupby([\"pacbioRun\", \"strand_exchange\"], as_index=False)\n",
    "    .aggregate(n_CCSs=pd.NamedAgg(\"query_name\", \"count\"))\n",
    "    .assign(\n",
    "        fraction=lambda x: x[\"n_CCSs\"]\n",
    "        / x.groupby(\"pacbioRun\")[\"n_CCSs\"].transform(\"sum\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# plot summary stats\n",
    "strand_exchange_chart = (\n",
    "    alt.Chart(strand_exchange_stats)\n",
    "    .encode(\n",
    "        x=\"n_CCSs:Q\",\n",
    "        y=alt.Y(\n",
    "            \"strand_exchange:N\",\n",
    "            axis=alt.Axis(title=None),\n",
    "        ),\n",
    "        facet=alt.Facet(\"pacbioRun\", columns=2, title=None),\n",
    "        tooltip=strand_exchange_stats.columns.tolist(),\n",
    "    )\n",
    "    .mark_bar()\n",
    "    .properties(width=250, height=100)\n",
    "    .resolve_scale(x=\"independent\")\n",
    ")\n",
    "display(strand_exchange_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b01ef8-7a32-4876-a29e-624f63df5f24",
   "metadata": {
    "tags": []
   },
   "source": [
    "Filter out CCSs with strand exchange. Note that this approach is only expected to catch ~half of CCSs with strand exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c262ec-bf03-43c9-a2a0-142b949cbf76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"There are {len(aligned_ccs)} before filtering.\")\n",
    "aligned_ccs = aligned_ccs.query('strand_exchange != \"strand exchange\"')\n",
    "print(f\"There are {len(aligned_ccs)} after filtering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350acb01-fb80-43ba-b175-3c661f076f61",
   "metadata": {},
   "source": [
    "## Filter CCSs for accuracy\n",
    "\n",
    "Plot the gene and barcode accuracy for each CCS, and only keep those above an accuracy threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e8181-d2d5-49eb-b263-d956dbdb57e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_error_rate = config[\"max_ccs_error_rate\"]  # require error rate <= this to keep CCS\n",
    "\n",
    "log10_error_floor = -7  # error rates less than this set to this for plotting\n",
    "log10_error_ceil = -2  # error rates greater than this set to this for plotting\n",
    "nbins = 100  # bins for cumulative fraction plot\n",
    "\n",
    "# calculate error rates\n",
    "aligned_ccs = aligned_ccs.assign(\n",
    "    gene_error=lambda x: 1 - x[\"gene_accuracy\"],\n",
    "    barcode_error=lambda x: 1 - x[\"barcode_accuracy\"],\n",
    ")\n",
    "\n",
    "# calculate cumulative frequencies on log error rates\n",
    "cumfrac = (\n",
    "    aligned_ccs.melt(\n",
    "        id_vars=[\"query_name\", \"pacbioRun\"],\n",
    "        value_vars=[\"barcode_error\", \"gene_error\"],\n",
    "        value_name=\"error\",\n",
    "    )\n",
    "    .assign(log10_error=lambda x: numpy.log10(x[\"error\"]).clip(lower=log10_error_floor))\n",
    "    .groupby([\"variable\", \"pacbioRun\"])\n",
    "    .apply(\n",
    "        lambda g: pd.DataFrame(\n",
    "            {\n",
    "                \"cumulative_count\": scipy.stats.cumfreq(\n",
    "                    g[\"log10_error\"],\n",
    "                    numbins=nbins,\n",
    "                    defaultreallimits=(log10_error_floor, log10_error_ceil),\n",
    "                )[0],\n",
    "                \"log10_error\": numpy.linspace(\n",
    "                    log10_error_floor, log10_error_ceil, nbins\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        meets_accuracy_cutoff=lambda x: x[\"log10_error\"] <= numpy.log10(max_error_rate),\n",
    "        cumulative_fraction=lambda x: x[\"cumulative_count\"] / len(aligned_ccs),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# plot cumulative frequencies\n",
    "cumfrac_chart = (\n",
    "    alt.Chart(cumfrac)\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"log10_error\",\n",
    "            scale=alt.Scale(zero=False),\n",
    "        ),\n",
    "        y=\"cumulative_count\",\n",
    "        color=\"meets_accuracy_cutoff\",\n",
    "        column=alt.Column(\"variable\", title=None),\n",
    "        row=alt.Row(\"pacbioRun\", title=None),\n",
    "        tooltip=[\n",
    "            alt.Tooltip(\"log10_error\", format=\".3f\"),\n",
    "            alt.Tooltip(\"cumulative_fraction\", format=\".3f\"),\n",
    "            alt.Tooltip(\"cumulative_count\", format=\".4g\"),\n",
    "        ],\n",
    "    )\n",
    "    .mark_point(filled=True, size=30)\n",
    "    .properties(width=225, height=120)\n",
    ")\n",
    "display(cumfrac_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9988e505-073b-4145-a74d-61fbab31af0d",
   "metadata": {},
   "source": [
    "Remove CCSs that do not meet accuracy threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fa65e-c9c2-4cdb-ae6f-20605e24867f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"There are {len(aligned_ccs)} CCSs before accuracy filtering.\")\n",
    "aligned_ccs = aligned_ccs.query(\"barcode_error <= @max_error_rate\").query(\n",
    "    \"gene_error <= @max_error_rate\"\n",
    ")\n",
    "print(f\"After filtering {len(aligned_ccs)} CCSs remain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87e522-ecb6-4a64-922a-28f998450a12",
   "metadata": {},
   "source": [
    "## Convert in-frame deletions to substitutions\n",
    "If a deletion is in-frame, convert to substitution format using `-` as the substitution character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3520f-d8db-4e5c-a434-032151a6c772",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deltosubs = alignparse.utils.InFrameDeletionsToSubs(geneseq)\n",
    "\n",
    "aligned_ccs = (\n",
    "    aligned_ccs.assign(\n",
    "        mutations_inframe=lambda x: x[\"gene_mutations\"].map(deltosubs.dels_to_subs),\n",
    "        inframe_deletion=lambda x: x[\"gene_mutations\"] != x[\"mutations_inframe\"],\n",
    "    )\n",
    "    .drop(columns=\"gene_mutations\")\n",
    "    .rename(columns={\"mutations_inframe\": \"gene_mutations\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586faea-2f2f-475a-b1b2-80e3b285ef68",
   "metadata": {},
   "source": [
    "How many CCSs have in-frame deletions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97faad39-19fe-4920-aebf-d5e73ceba957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of CCSs with in-frame deletions:\")\n",
    "display(\n",
    "    aligned_ccs.groupby(\"inframe_deletion\")\n",
    "    .aggregate(n_CCSs=pd.NamedAgg(\"query_name\", \"count\"))\n",
    "    .assign(fraction=lambda x: x[\"n_CCSs\"] / x[\"n_CCSs\"].sum())\n",
    "    .round(3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada702ee-bfd2-4393-8b01-8352a20dc101",
   "metadata": {},
   "source": [
    "## Empirical accuracy of CCSs\n",
    "We can compute the empirical accuracy of individual CCSs by comparing mutations found in CCSs with the same barcode.\n",
    "\n",
    "First, annotate which CCSs have indels (not in frame):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d486850-06a1-45fb-92b9-ae9a415d8c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_ccs = alignparse.consensus.add_mut_info_cols(\n",
    "    aligned_ccs,\n",
    "    mutation_col=\"gene_mutations\",\n",
    "    n_indel_col=\"n_indels\",\n",
    "    overwrite_cols=True,\n",
    ").assign(has_indel=lambda x: x[\"n_indels\"] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c3de-5f32-4941-b7d1-3bd6faca5882",
   "metadata": {},
   "source": [
    "Now compute empirical accuracy, for all sequences and only those without indels, and at the error-rate filter we chose to use and one 10-fold higher.\n",
    "Note that the in-frame codon deletions are not classified as deletions since we have re-classified as substitutions above.\n",
    "The empirical accuracy is the estimated accuracy of each **individual** CCS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ef04ef-bce4-4956-ac1a-6cfb8ba370e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute empirical accuracies\n",
    "empirical_acc = []\n",
    "for no_indel, acc_10x in itertools.product([True, False], [True, False]):\n",
    "    df = aligned_ccs.copy()\n",
    "    if not no_indel:\n",
    "        df = df.query(\"n_indels == 0\")\n",
    "        label = \"no indels\"\n",
    "    else:\n",
    "        label = \"allow indels\"\n",
    "    if acc_10x:\n",
    "        max_error_rate_10x = max_error_rate / 10\n",
    "        df = df.query(\"barcode_error <= @max_error_rate_10x\").query(\n",
    "            \"gene_error <= @max_error_rate_10x\"\n",
    "        )\n",
    "        label += \", 10x accuracy\"\n",
    "    for pacbioRun, run_df in df.groupby(\"pacbioRun\"):\n",
    "        empirical_acc.append(\n",
    "            alignparse.consensus.empirical_accuracy(\n",
    "                run_df, upstream_group_cols=None, mutation_col=\"gene_mutations\"\n",
    "            ).assign(label=label, pacbioRun=pacbioRun)\n",
    "        )\n",
    "empirical_acc = pd.concat(empirical_acc, ignore_index=True)\n",
    "\n",
    "# plot empirical accuracy\n",
    "print(\"Empirical accuracies:\")\n",
    "empirical_acc_chart = (\n",
    "    alt.Chart(empirical_acc)\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"accuracy:Q\",\n",
    "            scale=alt.Scale(domain=(0, 1)),\n",
    "        ),\n",
    "        y=alt.Y(\n",
    "            \"label:N\",\n",
    "            axis=alt.Axis(title=None),\n",
    "        ),\n",
    "        facet=alt.Facet(\n",
    "            \"pacbioRun\",\n",
    "            title=None,\n",
    "            columns=2,\n",
    "        ),\n",
    "        tooltip=[alt.Tooltip(\"accuracy\", format=\".3f\")],\n",
    "    )\n",
    "    .mark_point(filled=True, size=75)\n",
    "    .properties(width=225, height=65)\n",
    ")\n",
    "display(empirical_acc_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeeaac0-b3d8-4125-8df7-3baeb4be36cb",
   "metadata": {},
   "source": [
    "## Rarefaction and other estimates of library diversity\n",
    "To help understand how many barcodes there are and how evenly the number of reads are distributed among these barcodes, we make rarefaction curves. \n",
    "We also compute a few other metrics of diversity:\n",
    " 1. number of barcodes observed >$n$ times up to the minimum number of CCSs required to call a consensus below.\n",
    " 2. [inverse Simpson index](https://en.wikipedia.org/wiki/Diversity_index#Simpson_index), which is reciprocal of probability two randomly drawn sequences have same barcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8195ddbf-c7a2-4fb5-b584-0ca0ff1632d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# required CCSs per barcode to call consensus below\n",
    "min_support = config[\"consensus_params\"][\"min_support\"]\n",
    "\n",
    "\n",
    "# number of counts for each library / barcode\n",
    "barcodecounts = aligned_ccs.groupby([\"library\", \"barcode\"], as_index=False).aggregate(\n",
    "    count=pd.NamedAgg(\"query_name\", \"count\")\n",
    ")\n",
    "\n",
    "# make rarefaction plot\n",
    "rarefy_df = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            dms_variants.barcodes.rarefyBarcodes(\n",
    "                df, maxpoints=1000, logspace=False\n",
    "            ).assign(library=library)\n",
    "        )\n",
    "        for library, df in barcodecounts.groupby(\"library\")\n",
    "    ]\n",
    ")\n",
    "rarefy_chart = (\n",
    "    alt.Chart(rarefy_df)\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"ncounts\",\n",
    "            title=\"number of CCSs\",\n",
    "        ),\n",
    "        y=alt.X(\n",
    "            \"nbarcodes\",\n",
    "            title=\"number of barcodes\",\n",
    "        ),\n",
    "        color=alt.Color(\"library\"),\n",
    "        tooltip=rarefy_df.columns.tolist(),\n",
    "    )\n",
    "    .mark_point(size=10, filled=True)\n",
    "    .resolve_scale(y=\"independent\")\n",
    "    .properties(height=175, width=300)\n",
    ")\n",
    "display(rarefy_chart)\n",
    "\n",
    "# compute diversity statistics\n",
    "diversity = dms_variants.barcodes.inverse_simpson_index(barcodecounts).melt(\n",
    "    id_vars=\"library\",\n",
    "    value_vars=\"inverse_simpson_index\",\n",
    "    var_name=\"metric\",\n",
    "    value_name=\"diversity\",\n",
    ")\n",
    "for n in range(min_support):\n",
    "    diversity = pd.concat(\n",
    "        [\n",
    "            diversity,\n",
    "            barcodecounts.query(\"count > @n\")\n",
    "            .groupby(\"library\", as_index=False)\n",
    "            .aggregate(diversity=pd.NamedAgg(\"barcode\", \"nunique\"))\n",
    "            .assign(metric=f\"barcodes with >{n} CCSs\"),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "diversity_chart = (\n",
    "    alt.Chart(diversity)\n",
    "    .encode(\n",
    "        x=alt.X(\"diversity\"),\n",
    "        y=alt.Y(\"metric\", title=None),\n",
    "        facet=alt.Facet(\"library\", columns=2, title=None),\n",
    "        tooltip=diversity.columns.tolist(),\n",
    "    )\n",
    "    .mark_bar()\n",
    "    .properties(width=200, height=15 * (min_support + 1))\n",
    ")\n",
    "display(diversity_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23564ffd-6b32-4d3c-9ae9-add609120a5e",
   "metadata": {},
   "source": [
    "## Build consensus sequences\n",
    "Use the [alignparse.consensus.simple_mutconsensus](https://jbloomlab.github.io/alignparse/alignparse.consensus.html#alignparse.consensus.simple_mutconsensus) method to build consensus sequences, and plot how many barcodes and CCSs contributed to valid consensuses or had to be dropped.\n",
    "Note the stats for barcodes and CCSs look different, because there are uneven numbers of CCSs per barcode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9a335-d309-45f3-97d0-6f1c790b03e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get parameters for building consensus\n",
    "consensus_params = config[\"consensus_params\"]\n",
    "print(\n",
    "    \"Building consensus sequences with following settings\\n  \"\n",
    "    + \"\\n  \".join(f\"{param}={val}\" for param, val in consensus_params.items())\n",
    ")\n",
    "\n",
    "# build consensus sequences and plot results\n",
    "max_plot_nseqs = 15  # group nseqs >= this together\n",
    "plot_width = 225\n",
    "\n",
    "consensus, dropped = alignparse.consensus.simple_mutconsensus(\n",
    "    aligned_ccs, mutation_col=\"gene_mutations\", **consensus_params\n",
    ")\n",
    "\n",
    "consensus_stats = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            consensus.rename(columns={\"variant_call_support\": \"nseqs\"})\n",
    "            .drop(columns=\"gene_mutations\")\n",
    "            .assign(drop_reason=\"retained\", dropped=False),\n",
    "            dropped.assign(dropped=True),\n",
    "        ]\n",
    "    )\n",
    "    .assign(nseqs=lambda x: x[\"nseqs\"].clip(upper=max_plot_nseqs))\n",
    "    .groupby([\"library\", \"drop_reason\", \"dropped\", \"nseqs\"], as_index=False)\n",
    "    .aggregate(\n",
    "        n_barcodes=pd.NamedAgg(\"barcode\", \"count\"),\n",
    "        n_CCSs=pd.NamedAgg(\"nseqs\", \"sum\"),\n",
    "    )\n",
    "    .rename(columns={\"drop_reason\": \"category\"})\n",
    "    .melt(\n",
    "        id_vars=[\"library\", \"category\", \"dropped\", \"nseqs\"],\n",
    "        value_vars=[\"n_barcodes\", \"n_CCSs\"],\n",
    "        var_name=\"type_of_count\",\n",
    "        value_name=\"count\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# get drop reasons in order to plot\n",
    "drop_reasons = (\n",
    "    consensus_stats.groupby([\"category\", \"dropped\"], as_index=False)\n",
    "    .aggregate({\"count\": \"sum\"})\n",
    "    .sort_values([\"dropped\", \"count\"], ascending=[True, False])[\"category\"]\n",
    "    .tolist()\n",
    ")\n",
    "drop_colors = [\"blue\", \"orange\", \"orangered\", \"goldenrod\", \"gold\", \"darkorange\"]\n",
    "assert len(drop_reasons) <= len(drop_colors)\n",
    "\n",
    "consensus_stats_chart = (\n",
    "    alt.Chart(consensus_stats)\n",
    "    .encode(\n",
    "        x=alt.X(\n",
    "            \"nseqs\",\n",
    "            scale=alt.Scale(domain=(1, max_plot_nseqs)),\n",
    "            title=\"number of CCSs for barcode\",\n",
    "        ),\n",
    "        y=alt.Y(\"count\", stack=True),\n",
    "        color=alt.Color(\n",
    "            \"category\",\n",
    "            sort=drop_reasons,\n",
    "            scale=alt.Scale(range=drop_colors),\n",
    "        ),\n",
    "        row=alt.Row(\n",
    "            \"library\",\n",
    "            title=None,\n",
    "        ),\n",
    "        column=alt.Column(\"type_of_count\"),\n",
    "        tooltip=consensus_stats.columns.tolist(),\n",
    "    )\n",
    "    .mark_bar(size=0.75 * plot_width / max_plot_nseqs)\n",
    "    .properties(width=plot_width, height=120)\n",
    "    .configure_axis(grid=False)\n",
    "    .resolve_scale(y=\"independent\")\n",
    ")\n",
    "\n",
    "display(consensus_stats_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f578f-25e1-4dcc-bdc9-219cde993d78",
   "metadata": {},
   "source": [
    "## Write consensus sequences to barcode-variant lookup tables for subsequent use\n",
    "We filter any consensus sequences with indels that are not in-frame codon-length deletions, and then write the remaining sequences to barcode-variant lookup tables for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954cb13-007c-4d03-beec-8f4001660704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annotate with information on mutation types\n",
    "consensus = alignparse.consensus.add_mut_info_cols(\n",
    "    consensus,\n",
    "    mutation_col=\"gene_mutations\",\n",
    "    sub_str_col=\"substitutions\",\n",
    "    n_indel_col=\"n_indels\",\n",
    ")\n",
    "\n",
    "# plot summary stats\n",
    "stats = (\n",
    "    consensus.assign(\n",
    "        out_of_frame_indel=lambda x: x[\"n_indels\"] > 0,\n",
    "        in_frame_codon_deletion=lambda x: (\n",
    "            (~x[\"out_of_frame_indel\"]) & (x[\"substitutions\"].str.contains(\"-\"))\n",
    "        ),\n",
    "        no_indel=lambda x: (~x[\"out_of_frame_indel\"]) & (~x[\"in_frame_codon_deletion\"]),\n",
    "    )[[\"library\", \"out_of_frame_indel\", \"in_frame_codon_deletion\", \"no_indel\"]]\n",
    "    .groupby(\"library\", as_index=False)\n",
    "    .aggregate(\"sum\")\n",
    "    .melt(\n",
    "        id_vars=\"library\",\n",
    "        var_name=\"category\",\n",
    "        value_name=\"n_barcodes\",\n",
    "    )\n",
    "    .assign(retained=lambda x: x[\"category\"] != \"out_of_frame_indel\")\n",
    ")\n",
    "stats_chart = (\n",
    "    alt.Chart(stats)\n",
    "    .encode(\n",
    "        x=alt.X(\"n_barcodes\"),\n",
    "        y=alt.Y(\"category\", title=None),\n",
    "        color=alt.Color(\"retained\"),\n",
    "        tooltip=stats.columns.tolist(),\n",
    "        facet=alt.Facet(\"library\", columns=2),\n",
    "    )\n",
    "    .mark_bar()\n",
    "    .properties(width=175, height=45)\n",
    ")\n",
    "display(stats_chart)\n",
    "\n",
    "# write to file\n",
    "consensus = consensus.query(\"n_indels == 0\")\n",
    "nt_variants = config[\"nt_variants\"]\n",
    "print(f\"Writing {len(df)} consensus sequences to {nt_variants}\")\n",
    "consensus.to_csv(\n",
    "    consensus[[\"library\", \"barcode\", \"substitutions\", \"variant_call_support\"]].to_csv(\n",
    "        nt_variants, index=False\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
